{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this problem you will be analysing time series data. Specifically, the data that you will be working with has been collecting via Pittsburgh's TrueTime system which is available publicly here http://truetime.portauthority.org/bustime/login.jsp. If you're interested, you can request an API key and collect the data yourself (the process is just submitting a form), however we've already collected some smaller subset of the available data for the purposes of this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 TrueTime dataset\n",
    "\n",
    "The bus data has been collected by querying the TrueTime API every minute. Each time, we make two requests: \n",
    "\n",
    "1. We request vehicle information for every bus running on the 61A, 61B, 61C, and 61D bus routes. \n",
    "2. We request all available time predictions for the CMU / Morewood bus stop in both outbound and inbound directions. \n",
    "\n",
    "The results are given as XML, which are consequently parsed and stored within a sqlite database with two tables, one for vehicles and one for predictions. The table for the vehicles is organized in the following manner.  \n",
    "\n",
    "| | **vehicles**             | \n",
    "|----------|-------------|\n",
    "| vid      | vehicle identifier |\n",
    "| tmstmp | date and time of the last positional update of the vehicle |\n",
    "| lat | latitude position of the vehicle in decimal degrees |\n",
    "| lon | longitude position of the vehicle in decimal degrees |\n",
    "| hdg | heading of vehicle as a 360 degree value (0 is north, 90 is east, 180 is south, and 270 is west |\n",
    "| pid | pattern ID of trip currently being executed | \n",
    "| rt | route that is currently being execute | \n",
    "| des | destination of the current trip | \n",
    "| pdist | linear distance (feet) vehicle has traveled into the current pattern |\n",
    "|  spd | speed as reported from the vehicle in miles per hour | \n",
    "| tablockid | TA's version of the scheduled block identifier for work currently behind performed |\n",
    "| tatripid | TA's version of the scheduled trip identifier for the vehicle's current trip |\n",
    "\n",
    "The table for the predictions is organized in the following manner\n",
    "\n",
    "| | **predictions** | \n",
    "|---|---|\n",
    "| tmstmp | date and time the prediction was generated |\n",
    "| typ | type of prediction (A for arrival, D for a departure) | \n",
    "| stpnm | display name of the stop for which this prediction was generated |\n",
    "| stpid | unique identifier representing the stop for which this prediction was generated |\n",
    "| vid | unique ID of the vehicle for which this prediction was generated |\n",
    "| dstp | linear distance (feet) left to be traveled by the vehicle before it reaches the stop for which this prediction was generated |\n",
    "| rt | route for which this prediction was generated | \n",
    "| rtdd | language-specific route designator meant for display |\n",
    "| rtdir | direction of travel of the route associated with this prediction |\n",
    "| des | final destination of the vehicle associated with this prediction |\n",
    "| prdtm | predicted date and time of a vehicle's arrival or departure to the stop associated with this prediction | \n",
    "| dly | true if the vehicle is delayed, only present if the vehicle that generated this prediction is delayed | \n",
    "| tablockid | TA's version of the scheduled block identifier for work currently behind performed |\n",
    "| tatripid | TA's version of the scheduled trip identifier for the vehicle's current trip |\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you will need to read in the data. We have dumped the raw form of the data into a sqlite database, which you can read directly into a pandas dataframe. \n",
    "\n",
    "Since this data has not been processed at all by the course staff, you will need to fix and canonicalize a few things. \n",
    "\n",
    "### Specification\n",
    "\n",
    "1. Sometimes the TrueTime API returns a bogus result that has all the attributes but empty strings for all the values. You should inspect the data for clearly useless entries and remove all offending rows. \n",
    "\n",
    "2. If you check the datatype of each column, you'll notice that most columns are stored as objects. However, some of these columns are in fact integers or floats, and if you wish to run numerical functions on them (like numpy) you'll need to convert the columns to the correct type. Note that strings show up as objects. This is because the underlying implementation of Pandas uses numpy arrays, which need fixed-size entries, so they store pointers to strings. Your dataframe datatypes should match the following order and types (your datatypes may be 32bit instead of 64bit depending on your platform): \n",
    "\n",
    "   ```python\n",
    "   >>> vdf.dtypes\n",
    "   vid                   int64\n",
    "   tmstmp       datetime64[ns]\n",
    "   lat                 float64\n",
    "   lon                 float64\n",
    "   hdg                   int64\n",
    "   pid                   int64\n",
    "   rt                   object\n",
    "   des                  object\n",
    "   pdist                 int64\n",
    "   spd                   int64\n",
    "   tablockid            object\n",
    "   tatripid              int64\n",
    "   dtype: object\n",
    "\n",
    "   >>> pdf.dtypes\n",
    "   tmstmp       datetime64[ns]\n",
    "   typ                  object\n",
    "   stpnm                object\n",
    "   stpid                 int64\n",
    "   vid                   int64\n",
    "   dstp                  int64\n",
    "   rt                   object\n",
    "   rtdd                 object\n",
    "   rtdir                object\n",
    "   des                  object\n",
    "   prdtm        datetime64[ns]\n",
    "   dly                    bool\n",
    "   tablockid            object\n",
    "   tatripid              int64\n",
    "   dtype: object\n",
    "   ```\n",
    "\n",
    "3. As you may have noticed from the above data types, you should convert all timestamps to Pandas datetime objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    \"\"\" Read the given database into two pandas dataframes. \n",
    "    \n",
    "    Args: \n",
    "        fname (string): filename of sqlite3 database to read\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame, pd.DataFrame): a tuple of two dataframes, the first for the vehicle data and the \n",
    "                                      second for the prediction data. \n",
    "    \"\"\"\n",
    "    con = sqlite3.connect(fname)\n",
    "    vdf = pd.read_sql_query(\"SELECT * from vehicles\", con)\n",
    "    pdf = pd.read_sql_query(\"SELECT * from predictions\", con)\n",
    "    vdf = vdf.replace('', np.nan)\n",
    "    vdf = vdf.dropna(how = \"any\")\n",
    "    d = {'true': True, '': False}\n",
    "    pdf['dly']=pdf['dly'].map(d)\n",
    "    pdf = pdf.replace('', np.nan)\n",
    "    pdf = pdf.dropna(how = \"any\")\n",
    "    #pdf =pdf.dropna()\n",
    "    \n",
    "    vdf['tmstmp'] =  pd.to_datetime(vdf['tmstmp'], format='%Y%m%d %H:%M')\n",
    "    vdf[['lon','lat']] = vdf[['lon','lat']].apply(pd.to_numeric)\n",
    "    vdf[['vid','hdg','pid','pdist','spd','tatripid']] = vdf[['vid','hdg','pid','pdist','spd','tatripid']].astype(int)\n",
    "    pdf['tmstmp'] =  pd.to_datetime(pdf['tmstmp'], format='%Y%m%d %H:%M')\n",
    "    pdf['prdtm'] =  pd.to_datetime(pdf['prdtm'], format='%Y%m%d %H:%M')\n",
    "    \n",
    "    pdf[['vid','stpid','dstp','tatripid']] = pdf[['vid','stpid','dstp','tatripid']].astype(int)\n",
    "\n",
    "    #print s\n",
    "    #pd.to_numeric(s, errors='coerce')\n",
    "    #print s\n",
    "    #vdf.to_numeric(s, errors='ignore')\n",
    "    # verify that result of SQL query is stored in the dataframe\n",
    "    #print(vdf.head())\n",
    "    #print(pdf.head())\n",
    "    con.close()\n",
    "    return vdf,pdf\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vid                   int64\n",
      "tmstmp       datetime64[ns]\n",
      "lat                 float64\n",
      "lon                 float64\n",
      "hdg                   int64\n",
      "pid                   int64\n",
      "rt                   object\n",
      "des                  object\n",
      "pdist                 int64\n",
      "spd                   int64\n",
      "tablockid            object\n",
      "tatripid              int64\n",
      "dtype: object\n",
      "tmstmp       datetime64[ns]\n",
      "typ                  object\n",
      "stpnm                object\n",
      "stpid                 int64\n",
      "vid                   int64\n",
      "dstp                  int64\n",
      "rt                   object\n",
      "rtdd                 object\n",
      "rtdir                object\n",
      "des                  object\n",
      "prdtm        datetime64[ns]\n",
      "dly                    bool\n",
      "tablockid            object\n",
      "tatripid              int64\n",
      "dtype: object\n",
      "215473 143345\n",
      "    vid              tmstmp        lat        lon  hdg   pid   rt        des  \\\n",
      "0  5549 2016-08-11 10:56:00  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
      "1  5287 2016-08-11 10:56:00  40.438016 -79.927380   83  4521  61A  Swissvale   \n",
      "2  6114 2016-08-11 10:56:00  40.418897 -79.883970  128  4521  61A  Swissvale   \n",
      "3  5646 2016-08-11 10:56:00  40.441155 -79.892990  274  4663  61A   Downtown   \n",
      "4  5443 2016-08-11 10:56:00  40.436370 -79.968362  269  4663  61A   Downtown   \n",
      "\n",
      "   pdist  spd tablockid  tatripid  \n",
      "0   1106    0  061A-164      6691  \n",
      "1  22921   20  061A-163      6687  \n",
      "2  48014   12  061A-162      6683  \n",
      "3  15953   23  061A-166      6433  \n",
      "4  40770   30  061A-165      6430  \n",
      "               tmstmp typ                         stpnm  stpid   vid   dstp  \\\n",
      "0 2016-08-11 10:56:00   A   Forbes Ave opp Morewood Ave   7117  3201    398   \n",
      "1 2016-08-11 10:56:00   A  Forbes Ave past Morewood Ave   4407  6121   8004   \n",
      "2 2016-08-11 10:56:00   A  Forbes Ave past Morewood Ave   4407  3244  13925   \n",
      "3 2016-08-11 10:56:00   A   Forbes Ave opp Morewood Ave   7117  3202  11981   \n",
      "4 2016-08-11 10:56:00   A   Forbes Ave opp Morewood Ave   7117  3249  14013   \n",
      "\n",
      "    rt rtdd     rtdir                des               prdtm    dly tablockid  \\\n",
      "0  61D  61D  OUTBOUND  Murray-Waterfront 2016-08-11 10:57:00  False  061D-276   \n",
      "1  61C  61C   INBOUND           Downtown 2016-08-11 11:05:00  False  061C-232   \n",
      "2  61B  61B   INBOUND           Downtown 2016-08-11 11:08:00  False  061B-196   \n",
      "3  61B  61B  OUTBOUND          Braddock  2016-08-11 11:09:00  False  061B-195   \n",
      "4  61C  61C  OUTBOUND        McKeesport  2016-08-11 11:10:00  False  061C-229   \n",
      "\n",
      "   tatripid  \n",
      "0      6688  \n",
      "1      7377  \n",
      "2      5744  \n",
      "3      6689  \n",
      "4      6690  \n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "vdf, pdf = load_data('bus_aug23.db')\n",
    "\n",
    "\n",
    "# Inspect the datatypes of the dataframe\n",
    "print vdf.dtypes\n",
    "print pdf.dtypes\n",
    "\n",
    "print len(vdf), len(pdf)\n",
    "\n",
    "# Inspect the first five entries of the dataframe\n",
    "print vdf.head()\n",
    "print pdf.head()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Splitting Trips\n",
    "\n",
    "For this assignment, we will focus on the vehicles dataframe and come back to the predictions later. The next thing we will do is take the dataframe of vehicles and and split it into individual trips. Specifically, a trip is the sequence of rows corresponding to a single bus, typically at one minute intervals, from the start of its route to the end of its route. We will represent each trip as an individual dataframe, and create a list of dataframes for each trip. \n",
    "\n",
    "### Specification\n",
    "1. All entries in a trip should belong to a single route, destination, pattern, and bus. \n",
    "\n",
    "2. The entries in a trip should have (not strictly) monotonically increasing timestamps and distance traveled. \n",
    "\n",
    "3. Each trip should have the timestamp set as the index, named `tmstmp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should verify that your code meets the specification above. Use this cell to write tests that check the validity of your resulting output. For example,you should test that the total number of datapoints in the list of dataframes is the same as the number of datapoints in the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_trips(df):\n",
    "    \"\"\" Splits the dataframe of vehicle data into a list of dataframes for each individual trip. \n",
    "    \n",
    "    Args: \n",
    "        df (pd.DataFrame): A dataframe containing TrueTime bus data\n",
    "        \n",
    "    Returns: \n",
    "        (list): A list of dataframes, where each dataFrame contains TrueTime bus data for a single bus running a\n",
    "    \"\"\"\n",
    "    #print df.dtypes\n",
    "    #df =df.sort_values(by=['vid','rt','des','pid'])\n",
    "\n",
    "    #df.set_index(keys=['vid'], drop=False,inplace=True)\n",
    "\n",
    "    vidList=df['vid'].unique().tolist()\n",
    "    rtList=df['rt'].unique().tolist()\n",
    "    desList=df['des'].unique().tolist()\n",
    "    pidList=df['pid'].unique().tolist()\n",
    "    #print desList\n",
    "    #print df.loc[df['vid']=='3202']\n",
    "    dfList = []\n",
    "    for vid in vidList:\n",
    "        for rt in rtList:\n",
    "            for des in desList:\n",
    "                for pid in pidList:\n",
    "                    tmp = df[(df['vid']==vid)&(df['pid']==pid) & (df['rt'] == rt)& (df['des']==des)]\n",
    "                    \n",
    "                    # & df['pid']==pid\n",
    "                    if not tmp.empty:\n",
    "                        rowNum =1\n",
    "                        while rowNum < tmp.shape[0]:\n",
    "                            if tmp.iloc[rowNum,8]<tmp.iloc[rowNum-1,8]:\n",
    "                                dfList.append(tmp.iloc[0:rowNum,:]) \n",
    "                                tmp = tmp.iloc[rowNum:,:]\n",
    "                                rowNum=0\n",
    "                            rowNum+=1\n",
    "                        dfList.append(tmp)\n",
    "                        #print tmp\n",
    "                        #print tmp\n",
    "                    #and \n",
    "    # AUTOLAB_IGNORE_START  \n",
    "#     print dfList[0]\n",
    "#     print dfList[1]\n",
    "#     print dfList[2]\n",
    "#     print dfList[3]\n",
    "    # AUTOLAB_IGNORE_STOP\n",
    "    #print len(dfList)\n",
    "    return dfList\n",
    "    pass\n",
    "# AUTOLAB_IGNORE_START    \n",
    "all_trips = { rt : split_trips(vdf[vdf[\"rt\"]==rt]) for rt in [\"61A\", \"61B\", \"61C\", \"61D\"] }\n",
    "\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test the validity of your code here\n",
    "#df = vdf[vdf[\"rt\"]==\"61A\"]\n",
    "#print df.head\n",
    "#print df.groupby(['vid', 'des','pid','rt']).apply(lambda x: x.order(ascending=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Sliding Averages\n",
    "\n",
    "Let's compute a basic statistic for time series / sequential data, which is the sliding average. Sliding averages are typically used to smooth out short-term fluctuations to see the long-term patterns. \n",
    "\n",
    "While it would be fairly simple to directly construct a list of all the sliding averages from the existing dataset, in reality, new TrueTime bus data is constantly being available every day. Thus, instead of storing an unbounded list of datapoints, we instead will construct a class which does constant time updates as new data comes in. \n",
    "\n",
    "### Specifications\n",
    "1. Your function should not use more than O(k) memory. \n",
    "2. Each update should do O(1) work. \n",
    "3. We will use a centered sliding average: we will average the k values both before and after, averaging a total of 2k+1 elements. Note that k=0 will just return the stream without any averaging. \n",
    "4. Since the average depends on both past and future elements, the `update` function will not be able to output anything useful for the first k elements. You should output `None` during these iterations. We suggest you signify the end of the stream by calling `update(None)` k times, during which you should output the last k sliding averages. \n",
    "4. When at the beginning or end of a list, just compute the average of elements that exist. \n",
    "5. As usual, you should test the correctness of your code. You can do this in the same cell or make a new cell.\n",
    "\n",
    "Note: you may find the `collections.deque` data structure to be helpful. \n",
    "\n",
    "Example: \n",
    "```python\n",
    ">>> compute_sliding_averages(pd.Series([1,2,3,4,5]),1)\n",
    "pdf.Series([1.5, 2.0, 3.0, 4.0, 4.5])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class SlidingAverage:\n",
    "    def __init__(self,k):\n",
    "        \"\"\" Initializes a sliding average calculator which keeps track of the average of the last k seen elements. \n",
    "        \n",
    "        Args: \n",
    "            k (int): the number of elements to average (the half-width of the sliding average window)\n",
    "        \"\"\"\n",
    "        self.d = deque()\n",
    "        self.k = k\n",
    "        self.currSum = None\n",
    "        self.count = 0\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def update(self,x):\n",
    "        \"\"\" Computes the sliding average after having seen element x \n",
    "        \n",
    "        Args:\n",
    "            x (float): the next element in the stream to view\n",
    "            \n",
    "        Returns: \n",
    "            (float): the new sliding average after having seen element x, if it can be calculated\n",
    "        \"\"\"\n",
    "        self.d.append(x)\n",
    "        if x is not None:\n",
    "            self.count+=1\n",
    "            if self.currSum is not None:\n",
    "                self.currSum += x\n",
    "            else:\n",
    "                self.currSum=x\n",
    "            \n",
    "        if len(self.d)> self.k:\n",
    "            tmp = self.d.popleft()\n",
    "            if tmp is not None:\n",
    "                self.currSum-=tmp\n",
    "                self.count -= 1\n",
    "            #print self.d, self.count, self.currSum\n",
    "            return self.currSum/self.count#print self.d, self.count, self.currSum\n",
    "            \n",
    "        elif len(self.d) < self.k:\n",
    "            return None\n",
    "        #print self.d, self.count, self.currSum\n",
    "\n",
    "        else:\n",
    "            if self.currSum is not None:\n",
    "                return self.currSum/self.count\n",
    "            else:\n",
    "                return None\n",
    "        pass\n",
    "    \n",
    "\n",
    "def compute_sliding_averages(s, k):\n",
    "    \"\"\" Computes the sliding averages for a given Pandas series using the SlidingAverage class. \n",
    "    \n",
    "    Args:\n",
    "        s (pd.Series): a Pandas series for which the sliding average needs to be calculated\n",
    "        k (int): the half-width of the sliding average window \n",
    "        \n",
    "    Returns:\n",
    "        (pd.Series): a Pandas series of the sliding averages\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if k == 0:\n",
    "        return s\n",
    "    \n",
    "    ret = []\n",
    "    cal = SlidingAverage(2*k+1)\n",
    "    size = len(s)\n",
    "    for i in xrange(k):\n",
    "         cal.update(None)\n",
    "\n",
    "    count = 0\n",
    "    for index, value in s.iteritems():\n",
    "        if count < k:\n",
    "            count+=1\n",
    "            cal.update(float(value))\n",
    "\n",
    "        elif count >= k:\n",
    "            ret.append(cal.update(float(value)))\n",
    "\n",
    "    for i in xrange(k):\n",
    "        #count+=1\n",
    "        tmp = cal.update(None)\n",
    "        if tmp is not None:\n",
    "            ret.append(tmp)  \n",
    "\n",
    "    return pd.Series(ret)\n",
    "\n",
    "    pass\n",
    "    \n",
    "\n",
    "# Test your code!\n",
    "compute_sliding_averages(pd.Series([1.0,3.0,5,3,1]),1)\n",
    "\n",
    "#test=compute_sliding_averages(y,15)\n",
    "#print len(y),len(test)\n",
    "# cal = SlidingAverage(3)\n",
    "# print cal.update(None)\n",
    "# # print cal.update(None)\n",
    "# print cal.update(1.0)\n",
    "# print cal.update(1.0)\n",
    "# print cal.update(2.0)\n",
    "# print cal.update(3.0)\n",
    "# print cal.update(4.0)\n",
    "# print cal.update(5.0)\n",
    "# print cal.update(None)\n",
    "# print cal.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 Time Series Visualizations\n",
    "\n",
    "Time series data is typically displayed as signals over time. For example, this could be the speed of the bus over time, or the number of minutes behind or ahead of schedule a bus is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Use svg backend for better quality\n",
    "# AUTOLAB_IGNORE_START\n",
    "matplotlib.use(\"svg\")\n",
    "# AUTOLAB_IGNORE_STOP\n",
    "import matplotlib.pyplot as plt\n",
    "# AUTOLAB_IGNORE_START\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0) # you should adjust this to fit your screen\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first example, you'll plot the speed of the bus as a function of time. Here, we'll overlay multiple routes on a single plot. Can you determine the direction of the bus (to or away from downtown) from the signal? \n",
    "\n",
    "### Specification:\n",
    "1. Plot the sliding average speed of each bus, using a new line for each bus. \n",
    "2. Return a list of the resulting `Line2D` objects plot. The order of the line objects should correspond with the order of the trips. \n",
    "3. Do not call `plt.show()` inside the function. Autolab will not X out of any plotted images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_trip(trips, k):\n",
    "    \"\"\" Plots the measured speed and sliding average speed as a function of time \n",
    "    \n",
    "    Args: \n",
    "        trip (list): list of trip DataFrames to plot\n",
    "        k (int): the half-width of the sliding average window\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    for trip in trips:\n",
    "        if trip is not None and 'tmstmp' in trip:\n",
    "            #print trip.head\n",
    "            x = trip['tmstmp']\n",
    "\n",
    "            y=compute_sliding_averages(trip['spd'], k)\n",
    "\n",
    "\n",
    "            ret.append(plt.plot(x,y,'-'))\n",
    "\n",
    "    \n",
    "    #print compute_sliding_averages(trips[0]['spd'], k)\n",
    "    #print trips[0]\n",
    "    return ret\n",
    "    pass\n",
    "\n",
    "\n",
    "# Play around with these values. Can you differentiate the buses going towards downtown from the buses going away from downtown?\n",
    "# AUTOLAB_IGNORE_START\n",
    "lines = plot_trip(all_trips['61A'][:20], 15)\n",
    "plt.show()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "We can also gain information from overall trends from averaging many data points. In the following function, you will plot the average speed of all buses at regular time intervals throughout the day. \n",
    "\n",
    "### Specification\n",
    "1. You should group the rows of the dataframe by taking the timestamp modulo t and ignoring the day/month/year (since the data was collected at 1 minute intervals, this means that t=1 corresponds to averaging one entry per day recorded).\n",
    "2. Return the PathCollection object of your plot. For example, if you create the plot using the matplotlib command `scatter(...)`, return the result of this function call. \n",
    "3. Do not call `plt.show()` inside the function. Autolab will not X out of any plotted images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f165e4e71d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# AUTOLAB_IGNORE_START\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mvdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bus_aug23.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_avg_spd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plot_avg_spd(df, t):\n",
    "    \"\"\" Plot the average speed of all recorded buses within t minute intervals \n",
    "    Args: \n",
    "        df (pd.DataFrame): dataframe of bus data\n",
    "        t (int): the granularity of each time period (in minutes) for which an average is speed is calculated\n",
    "    \"\"\"\n",
    "    \n",
    "    #df['tmstmp']=[time.time() for time in df['tmstmp']]\n",
    "    #df['tmstmp']=pd.to_datetime(df['tmstmp'], format='%H:%M')\n",
    "    #df['tmstmp']=pd.to_timedelta(df['tmstmp'])\n",
    "    #print df['tmstmp']\n",
    "    #times = pd.DatetimeIndex(vdf['tmstmp'])\n",
    "    \n",
    "    #x= vdf.groupby([times.hour, times.minute/10]).first()['tmstmp']\n",
    "    agg = df.groupby(df['tmstmp'].map(lambda x: (x.hour*60+ x.minute)/t)).mean()\n",
    "    y = agg['spd']\n",
    "    time = agg.index\n",
    "    x = []\n",
    "    for timeIndex in time:\n",
    "        timeIndex = t * timeIndex\n",
    "        hourStr = str(timeIndex/60)\n",
    "        hourStr =\"{0:0=2d}\".format(int(hourStr))\n",
    "        minuteStr = str(timeIndex%60)\n",
    "        minuteStr = \"{0:0=2d}\".format(int(minuteStr))\n",
    "        timeStr = hourStr +\":\"+minuteStr\n",
    "        currTime = pd.to_datetime(timeStr, format='%H:%M')\n",
    "        x.append(currTime.time())\n",
    "    #df.set_index('tmstmp', inplace=True)\n",
    "#     print df.groupby([df.index.map(lambda t: t.minute), 'spd']).mean()\n",
    "    #print (df.groupby(pd.TimeGrouper(freq))['spd'].mean())\n",
    "    return plt.scatter(x,y)\n",
    "    #print df.groupby((df.tmstmp.dt.hour *60 + df.tmstmp.dt.minute) % t).mean()['spd']\n",
    "    #plt.scatter(x,y)\n",
    "    #print df.tmstmp.dt.minute % t\n",
    "    #x = df.groupby(df.index.map(lambda x: x.time))['spd'].first().index\n",
    "    #y = df.groupby(df.index.map(lambda x: (x.hour+ x.minute))).mean()['spd']\n",
    "    #return plt.scatter(x,y)\n",
    "    pass\n",
    "\n",
    "# AUTOLAB_IGNORE_START\n",
    "vdf, pdf = load_data('bus_aug23.db')\n",
    "s = plot_avg_spd(vdf, 10)\n",
    "\n",
    "plt.show()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n"
     ]
    }
   ],
   "source": [
    "#vdf.set_index('tmstmp', inplace=True)\n",
    "#print vdf.groupby(vdf['tmstmp'].map(lambda x: (x.hour*60+ x.minute)/10)).mean()['spd']\n",
    "#print vdf['tmstmp'].head\n",
    "#print pd.to_datetime(vdf['tmstmp'], format='%H:%M')\n",
    "#print vdf.index.map(lambda x: str(x.hour)+\":\"+ str(x.minute%10))\n",
    "#by=[data.datetime_col.map(lambda x : x.hour),\n",
    "#                       data.datetime_col.map(lambda x : x.minute)]\n",
    "\n",
    "#print vdf.resample('10min', how='mean')\n",
    "#print vdf.groupby(by=[vdf['tmstmp'].map(lambda x: (x.hour)),vdf['tmstmp'].map(lambda x: ( x.minute))]).mean()['spd']\n",
    "# plt.scatter(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
