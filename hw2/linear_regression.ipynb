{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression [35pts (+5 bonus)]\n",
    "\n",
    "## Introduction\n",
    "One of the most widespread regression tools is the simple but powerful linear regression. In this notebook, you will engineer the Pittsburgh bus data into numerical features and use them to predict the number of minutes until the bus reaches the bus stop at Forbes and Morewood. \n",
    "\n",
    "Notebook restriction: you may not use scikit-learn for this notebook.  \n",
    "\n",
    "## Q1: Labeling the Dataset [8pts]\n",
    "\n",
    "You may have noticed that the Pittsburgh bus data has a predictions table with the TrueTime predictions on arrival time, however it does not have the true label: the actual number of minutes until a bus reaches Forbes and Morewood. You will have to generate this yourself. \n",
    "\n",
    "Using the `all_trips` function that you implemented in homework 2, you can split the dataframe into separate trips. You will first process each trip into a form more natural for the regression setting. For each trip, you will need to locate the point at which a bus passes the bus stop to get the time at which the bus passes the bus stop. From here, you can calculate the true label for all prior datapoints, and throw out the rest. \n",
    "\n",
    "### Importing functions from homework 2\n",
    "\n",
    "Using the menu in Jupyter, you can import code from your notebook as a Python script using the following steps: \n",
    "1. Click File -> Download as -> Python (.py)\n",
    "2. Save file (time_series.py) in the same directory as this notebook \n",
    "3. (optional) Remove all test code (i.e. lines between AUTOLAB_IGNORE macros) from the script for faster loading time\n",
    "4. Import from the notebook with `from time_series import function_name`\n",
    "\n",
    "### Specifications\n",
    "\n",
    "1. To determine when the bus passes Morewood, we will use the Euclidean distance as a metric to determine how close the bus is to the bus stop. \n",
    "2. We will assume that the row entry with the smallest Euclidean distance to the bus stop is when the bus reaches the bus stop, and that you should truncate all rows that occur **after** this entry.  In the case where there are multiple entries with the exact same minimal distance, you should just consider the first one that occurs in the trip (so truncate everything after the first occurance of minimal distance). \n",
    "3. Assume that the row with the smallest Euclidean distance to the bus stop is also the true time at which the bus passes the bus stop. Using this, create a new column called `eta` that contains for each row, the number of minutes until the bus passes the bus stop (so the last row of every trip will have an `eta` of 0).\n",
    "4. Make sure your `eta` is numerical and not a python timedelta object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "from collections import Counter\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "def load_data(fname):\n",
    "    \"\"\" Read the given database into two pandas dataframes. \n",
    "    \n",
    "    Args: \n",
    "        fname (string): filename of sqlite3 database to read\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame, pd.DataFrame): a tuple of two dataframes, the first for the vehicle data and the \n",
    "                                      second for the prediction data. \n",
    "    \"\"\"\n",
    "    con = sqlite3.connect(fname)\n",
    "    vdf = pd.read_sql_query(\"SELECT * from vehicles\", con)\n",
    "    pdf = pd.read_sql_query(\"SELECT * from predictions\", con)\n",
    "    vdf = vdf.replace('', np.nan)\n",
    "    vdf = vdf.dropna(how = \"any\")\n",
    "    d = {'true': True, '': False}\n",
    "    pdf['dly']=pdf['dly'].map(d)\n",
    "    pdf = pdf.replace('', np.nan)\n",
    "    pdf = pdf.dropna(how = \"any\")\n",
    "    #pdf =pdf.dropna()\n",
    "    \n",
    "    vdf['tmstmp'] =  pd.to_datetime(vdf['tmstmp'], format='%Y%m%d %H:%M')\n",
    "    vdf[['lon','lat']] = vdf[['lon','lat']].apply(pd.to_numeric)\n",
    "    vdf[['vid','hdg','pid','pdist','spd','tatripid']] = vdf[['vid','hdg','pid','pdist','spd','tatripid']].astype(int)\n",
    "    pdf['tmstmp'] =  pd.to_datetime(pdf['tmstmp'], format='%Y%m%d %H:%M')\n",
    "    pdf['prdtm'] =  pd.to_datetime(pdf['prdtm'], format='%Y%m%d %H:%M')\n",
    "    \n",
    "    pdf[['vid','stpid','dstp','tatripid']] = pdf[['vid','stpid','dstp','tatripid']].astype(int)\n",
    "\n",
    "    #print s\n",
    "    #pd.to_numeric(s, errors='coerce')\n",
    "    #print s\n",
    "    #vdf.to_numeric(s, errors='ignore')\n",
    "    # verify that result of SQL query is stored in the dataframe\n",
    "    #print(vdf.head())\n",
    "    #print(pdf.head())\n",
    "    con.close()\n",
    "    return vdf,pdf\n",
    "    pass\n",
    "def split_trips(df):\n",
    "    \"\"\" Splits the dataframe of vehicle data into a list of dataframes for each individual trip. \n",
    "    \n",
    "    Args: \n",
    "        df (pd.DataFrame): A dataframe containing TrueTime bus data\n",
    "        \n",
    "    Returns: \n",
    "        (list): A list of dataframes, where each dataFrame contains TrueTime bus data for a single bus running a\n",
    "    \"\"\"\n",
    "    #print df.dtypes\n",
    "    #df =df.sort_values(by=['vid','rt','des','pid'])\n",
    "\n",
    "    #df.set_index(keys=['vid'], drop=False,inplace=True)\n",
    "\n",
    "    def split(trip):\n",
    "        if not increasing(trip.tmstmp) or not increasing(trip.pdist):\n",
    "            trip = trip.sort_values(['tmstmp','pdist'],ascending=[True,True])\n",
    "        indices = [0]\n",
    "        i= 1\n",
    "        while i<len(trip):\n",
    "            if trip['pdist'].iloc[i]<trip['pdist'].iloc[i-1]:\n",
    "                indices.append(i)\n",
    "            i+=1\n",
    "        indices.append(i)\n",
    "        return [trip[a:b].set_index('tmstmp') for (a,b) in zip(indices[:-1],indices[1:])]\n",
    "    def increasing(L):\n",
    "        return all(x<=y for x,y in zip(L[:-1],L[1:]))\n",
    "    trips=[]\n",
    "    for vid in df['vid'].unique():\n",
    "        df0= df[df['vid']==vid]\n",
    "        for pid in df0['pid'].unique():\n",
    "            df1 = df0[df0['pid']==pid]\n",
    "            trips +=split(df1)\n",
    "    return trips\n",
    "\n",
    "vdf, _ = load_data('bus_train.db')\n",
    "\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "#print vdf.head()\n",
    "all_trips = split_trips(vdf)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4616\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_trips' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-05b5538fc066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# AUTOLAB_IGNORE_START\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mall_trips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_trips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmorewood_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m40.444671114203\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m79.94356058465502\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# def distance(row):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_trips' is not defined"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "print all_trips[0].head()\n",
    "df = all_trips[2]\n",
    "morewood_coordinates = (40.444671114203, -79.94356058465502)\n",
    "def distance(row):\n",
    "    return math.sqrt((row['lat']-morewood_coordinates[0])**2+(row['lon']-morewood_coordinates[1])**2)\n",
    "def eta(row):\n",
    "    #print row.name,arrival,type((row.name-arrival))\n",
    "    return (arrival-row.name).seconds/60\n",
    "df['eta'] = df.apply(distance,axis=1)\n",
    "#print df\n",
    "# arrival = df['eta'].idxmin(axis=1)\n",
    "#print df\n",
    "minIndex = 0\n",
    "i = 0\n",
    "dist = df['eta'].iloc[0]\n",
    "arrival = df.index[0]\n",
    "#print time\n",
    "for _,row in df.iterrows():\n",
    "    #print row\n",
    "    if row[11]<dist:\n",
    "        dist = row['eta']\n",
    "        minIndex = i\n",
    "        arrival = row.name\n",
    "    i+=1\n",
    "#print arrival\n",
    "df =    df.iloc[:minIndex+1]\n",
    "#df['tmstmp']=pd.Series({x:x for x in df.index}) \n",
    "df['eta'] = df.apply(eta,axis=1)\n",
    "#df.drop('euc', axis=1, inplace=True)\n",
    "print df\n",
    "# AUTOLAB_IGNORE_STOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yao\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 506, 21: 200, 18: 190, 20: 184, 19: 163, 16: 162, 22: 159, 17: 151, 23: 139, 31: 132, 15: 128, 2: 125, 34: 112, 32: 111, 33: 101, 28: 98, 14: 97, 30: 95, 35: 95, 29: 93, 24: 90, 25: 89, 37: 86, 27: 83, 39: 83, 38: 82, 36: 77, 26: 75, 40: 70, 13: 62, 41: 53, 44: 52, 42: 47, 6: 44, 5: 39, 12: 39, 46: 39, 7: 38, 3: 36, 45: 33, 47: 33, 43: 31, 48: 27, 4: 26, 49: 26, 11: 25, 50: 25, 10: 23, 51: 23, 8: 19, 9: 18, 53: 16, 54: 15, 52: 14, 55: 14, 56: 8, 57: 3, 58: 3, 59: 3, 60: 3, 61: 1, 62: 1, 67: 1})\n",
      "               tmstmp   vid        lat        lon  hdg   pid   rt        des  \\\n",
      "0 2016-08-11 10:56:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
      "1 2016-08-11 10:57:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
      "2 2016-08-11 10:58:00  5549  40.438842 -79.994733  124  4521  61A  Swissvale   \n",
      "3 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
      "4 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
      "\n",
      "   pdist  spd tablockid  tatripid  eta  \n",
      "0   1106    0  061A-164      6691   16  \n",
      "1   1106    0  061A-164      6691   15  \n",
      "2   1778    8  061A-164      6691   14  \n",
      "3   2934    7  061A-164      6691   13  \n",
      "4   2934    7  061A-164      6691   13  \n"
     ]
    }
   ],
   "source": [
    "def label_and_truncate(trip, bus_stop_coordinates):\n",
    "    \"\"\" Given a dataframe of a trip following the specification in the previous homework assignment,\n",
    "        generate the labels and throw away irrelevant rows. \n",
    "        \n",
    "        Args: \n",
    "            trip (dataframe): a dataframe from the list outputted by split_trips from homework 2\n",
    "            stop_coordinates ((float, float)): a pair of floats indicating the (latitude, longitude) \n",
    "                                               coordinates of the target bus stop. \n",
    "            \n",
    "        Return:\n",
    "            (dataframe): a labeled trip that is truncated at Forbes and Morewood and contains a new column \n",
    "                         called `eta` which contains the number of minutes until it reaches the bus stop. \n",
    "        \"\"\"\n",
    "    \n",
    "    def distance(row):\n",
    "        return math.sqrt((row['lat']-bus_stop_coordinates[0])**2+(row['lon']-bus_stop_coordinates[1])**2)\n",
    "    def eta(row):\n",
    "        #print row['tmstmp'],arrival,type((row['tmstmp']-arrival))\n",
    "        #print arrival, row.name\n",
    "        return (arrival-row.name).seconds/60\n",
    "    trip['eta'] = trip.apply(distance,axis=1)\n",
    "    #print df\n",
    "    \n",
    "    minIndex = 0\n",
    "    i = 0\n",
    "    dist = trip['eta'].iloc[0]\n",
    "    arrival = trip.index[0]\n",
    "    #print time\n",
    "    for _,row in trip.iterrows():\n",
    "        #print row\n",
    "        if row[11]<dist:\n",
    "            dist = row['eta']\n",
    "            minIndex = i\n",
    "            arrival = row.name\n",
    "        i+=1\n",
    "    #print arrival\n",
    "    trip =    trip.iloc[:minIndex+1]\n",
    "    trip['eta'] = trip.apply(eta,axis=1)\n",
    "    #trip =  trip.truncate(after =arrival)\n",
    "    \n",
    "    #df.drop('euc', axis=1, inplace=True)\n",
    "    #print df.head()\n",
    "    #print trip.shape[0]\n",
    "    return trip\n",
    "    pass\n",
    "    \n",
    "# # AUTOLAB_IGNORE_START\n",
    "# morewood_coordinates = (40.444671114203, -79.94356058465502) # (lat, lon)\n",
    "# #label_and_truncate(all_trips[0], morewood_coordinates)\n",
    "\n",
    "labeled_trips = [label_and_truncate(trip, morewood_coordinates) for trip in all_trips]\n",
    "labeled_vdf = pd.concat(labeled_trips).reset_index()\n",
    "print Counter([len(t) for t in labeled_trips])\n",
    "print labeled_vdf.head()\n",
    "# # AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our implementation, this returns the following output\n",
    "```python\n",
    ">>> Counter([len(t) for t in labeled_trips])\n",
    "Counter({1: 506, 21: 200, 18: 190, 20: 184, 19: 163, 16: 162, 22: 159, 17: 151, 23: 139, 31: 132, 15: 128, 2: 125, 34: 112, 32: 111, 33: 101, 28: 98, 14: 97, 30: 95, 35: 95, 29: 93, 24: 90, 25: 89, 37: 86, 27: 83, 39: 83, 38: 82, 36: 77, 26: 75, 40: 70, 13: 62, 41: 53, 44: 52, 42: 47, 6: 44, 5: 39, 12: 39, 46: 39, 7: 38, 3: 36, 45: 33, 47: 33, 43: 31, 48: 27, 4: 26, 49: 26, 11: 25, 50: 25, 10: 23, 51: 23, 8: 19, 9: 18, 53: 16, 54: 15, 52: 14, 55: 14, 56: 8, 57: 3, 58: 3, 59: 3, 60: 3, 61: 1, 62: 1, 67: 1}) \n",
    ">>> labeled_vdf.head()\n",
    "               tmstmp   vid        lat        lon  hdg   pid   rt        des  \\\n",
    "0 2016-08-11 10:56:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
    "1 2016-08-11 10:57:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
    "2 2016-08-11 10:58:00  5549  40.438842 -79.994733  124  4521  61A  Swissvale   \n",
    "3 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
    "4 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
    "\n",
    "   pdist  spd tablockid  tatripid  eta  \n",
    "0   1106    0  061A-164      6691   16  \n",
    "1   1106    0  061A-164      6691   15  \n",
    "2   1778    8  061A-164      6691   14  \n",
    "3   2934    7  061A-164      6691   13  \n",
    "4   2934    7  061A-164      6691   13 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Generating Basic Features [8pts]\n",
    "In order to perform linear regression, we need to have numerical features. However, not everything in the bus database is a number, and not all of the numbers even make sense as numerical features. If you use the data as is, it is highly unlikely that you'll achieve anything meaningful.\n",
    "\n",
    "Consequently, you will perform some basic feature engineering. Feature engineering is extracting \"features\" or statistics from your data, and hopefully improve the performance if your learning algorithm (in this case, linear regression). Good features can often make up for poor model selection and improve your overall predictive ability on unseen data. In essence, you want to turn your data into something your algorithm understands. \n",
    "\n",
    "### Specifications\n",
    "1. The input to your function will be a concatenation of the trip dataframes generated in Q1 with the index dropped (so same structure as the original dataframe, but with an extra column and less rows). \n",
    "2. Linear models typically have a constant bias term. We will encode this as a column of 1s in the dataframe. Call this column 'bias'. \n",
    "2. We will keep the following columns as is, since they are already numerical:  pdist, spd, lat, lon, and eta \n",
    "3. Time is a cyclic variable. To encode this as a numerical feature, we can use a sine/cosine transformation. Suppose we have a feature of value f that ranges from 0 to N. Then, the sine and cosine transformation would be $\\sin\\left(2\\pi \\frac{f}{N}\\right)$ and $\\cos\\left(2\\pi \\frac{f}{N}\\right)$. For example, the sine transformation of 6 hours would be $\\sin\\left(2\\pi \\frac{6}{24}\\right)$, since there are 24 hours in a cycle. You should create sine/cosine features for the following:\n",
    "    * day of week (cycles every week, 0=Monday)\n",
    "    * hour of day (cycles every 24 hours, 0=midnight)\n",
    "    * time of day represented by total number of minutes elapsed in the day (cycles every 60*24 minutes, 0=midnight).\n",
    "4. Heading is also a cyclic variable, as it is the ordinal direction in degrees (so cycles every 360 degrees). \n",
    "4. Buses run on different schedules on the weekday as opposed to the weekend. Create a binary indicator feature `weekday` that is 1 if the day is a weekday, and 0 otherwise. \n",
    "5. Route and destination are both categorical variables. We can encode these as indicator vectors, where each column represents a possible category and a 1 in the column indicates that the row belongs to that category. This is also known as a one hot encoding. Make a set of indicator features for the route, and another set of indicator features for the destination. \n",
    "6. The names of your indicator columns for your categorical variables should be exactly the value of the categorical variable. The pandas function `pd.DataFrame.get_dummies` will be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tmstmp   vid        lat        lon  hdg   pid   rt        des  \\\n",
      "0 2016-08-11 10:56:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
      "1 2016-08-11 10:57:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
      "2 2016-08-11 10:58:00  5549  40.438842 -79.994733  124  4521  61A  Swissvale   \n",
      "3 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
      "4 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
      "\n",
      "   pdist  spd tablockid  tatripid  eta  \n",
      "0   1106    0  061A-164      6691   16  \n",
      "1   1106    0  061A-164      6691   15  \n",
      "2   1778    8  061A-164      6691   14  \n",
      "3   2934    7  061A-164      6691   13  \n",
      "4   2934    7  061A-164      6691   13  \n"
     ]
    }
   ],
   "source": [
    "def create_features(vdf):\n",
    "    \"\"\" Given a dataframe of labeled and truncated bus data, generate features for linear regression. \n",
    "    \n",
    "        Args:\n",
    "            df (dataframe) : dataframe of bus data with the eta column and truncated rows\n",
    "        Return: \n",
    "            (dataframe) : dataframe of features for each example\n",
    "        \"\"\"\n",
    "    def weekday(t):\n",
    "        if t.dayofweek<5:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    features = pd.DataFrame()\n",
    "    features['pdist'] = vdf['pdist']\n",
    "    features['spd'] = vdf['spd']\n",
    "    features['lat'] = vdf['lat']\n",
    "    features['lon'] = vdf['lon']\n",
    "    features['eta'] = vdf['eta']\n",
    "    features['bias']=[1.0]*vdf.shape[0]\n",
    "    features['sin_hdg']=vdf['hdg'].apply(lambda x: math.sin(x*2*math.pi/360)) \n",
    "    features['cos_hdg']=vdf['hdg'].apply(lambda x: math.cos(x*2*math.pi/360))  \n",
    "    features['sin_day_of_week']=vdf['tmstmp'].apply(lambda x: math.sin(x.dayofweek*2*math.pi/7)) \n",
    "    features['cos_day_of_week']=vdf['tmstmp'].apply(lambda x: math.cos(x.dayofweek*2*math.pi/7)) \n",
    "    features['sin_hour_of_day']=vdf['tmstmp'].apply(lambda x: math.sin(x.hour*2*math.pi/24)) \n",
    "    features['cos_hour_of_day']=vdf['tmstmp'].apply(lambda x: math.cos(x.hour*2*math.pi/24))\n",
    "    features['sin_time_of_day']=vdf['tmstmp'].apply(lambda x: math.sin((60*x.hour+x.minute)*2*math.pi/1440)) \n",
    "    features['cos_time_of_day']=vdf['tmstmp'].apply(lambda x: math.cos((60*x.hour+x.minute)*2*math.pi/1440))\n",
    "    features['weekday']=vdf['tmstmp'].apply(weekday)\n",
    "    dest = vdf['des'].unique().tolist()\n",
    "    route = vdf['rt'].unique().tolist()\n",
    "    for des in dest:\n",
    "        features[des]=vdf['des'].apply(lambda x:1.0 if des == x else 0.0)\n",
    "    for rt in route:\n",
    "        features[rt]=vdf['rt'].apply(lambda x:1.0 if rt == x else 0.0)\n",
    "#     u'cos_hdg',   u'sin_day_of_week',\n",
    "#          u'cos_day_of_week',   u'sin_hour_of_day',   u'cos_hour_of_day',\n",
    "#          u'sin_time_of_day',   u'cos_time_of_day'\n",
    "    #print features\n",
    "    return features\n",
    "    pass\n",
    "\n",
    "# AUTOLAB_IGNORE_START\n",
    "print labeled_vdf.head()\n",
    "vdf_features = create_features(labeled_vdf)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([            u'pdist',               u'spd',               u'lat',\n",
      "                     u'lon',               u'eta',              u'bias',\n",
      "                 u'sin_hdg',           u'cos_hdg',   u'sin_day_of_week',\n",
      "         u'cos_day_of_week',   u'sin_hour_of_day',   u'cos_hour_of_day',\n",
      "         u'sin_time_of_day',   u'cos_time_of_day',           u'weekday',\n",
      "               u'Swissvale',          u'Downtown', u'Murray-Waterfront',\n",
      "               u'Braddock ',       u'McKeesport ',   u'Greenfield Only',\n",
      "                     u'61A',               u'61D',               u'61B',\n",
      "                     u'61C'],\n",
      "      dtype='object')\n",
      "   pdist  spd        lat        lon  eta  bias   sin_hdg   cos_hdg  \\\n",
      "0   1106    0  40.439504 -79.996981   16   1.0  0.913545 -0.406737   \n",
      "1   1106    0  40.439504 -79.996981   15   1.0  0.913545 -0.406737   \n",
      "2   1778    8  40.438842 -79.994733   14   1.0  0.829038 -0.559193   \n",
      "3   2934    7  40.437938 -79.991213   13   1.0  0.997564 -0.069756   \n",
      "4   2934    7  40.437938 -79.991213   13   1.0  0.997564 -0.069756   \n",
      "\n",
      "   sin_day_of_week  cos_day_of_week ...   Swissvale  Downtown  \\\n",
      "0         0.433884        -0.900969 ...         1.0       0.0   \n",
      "1         0.433884        -0.900969 ...         1.0       0.0   \n",
      "2         0.433884        -0.900969 ...         1.0       0.0   \n",
      "3         0.433884        -0.900969 ...         1.0       0.0   \n",
      "4         0.433884        -0.900969 ...         1.0       0.0   \n",
      "\n",
      "   Murray-Waterfront  Braddock   McKeesport   Greenfield Only  61A  61D  61B  \\\n",
      "0                0.0        0.0          0.0              0.0  1.0  0.0  0.0   \n",
      "1                0.0        0.0          0.0              0.0  1.0  0.0  0.0   \n",
      "2                0.0        0.0          0.0              0.0  1.0  0.0  0.0   \n",
      "3                0.0        0.0          0.0              0.0  1.0  0.0  0.0   \n",
      "4                0.0        0.0          0.0              0.0  1.0  0.0  0.0   \n",
      "\n",
      "   61C  \n",
      "0  0.0  \n",
      "1  0.0  \n",
      "2  0.0  \n",
      "3  0.0  \n",
      "4  0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "print vdf_features.columns\n",
    "print vdf_features.head()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation has the following output. Verify that your code has the following columns (order doesn't matter): \n",
    "```python\n",
    ">>> vdf_features.columns\n",
    "Index([             u'bias',             u'pdist',               u'spd',\n",
    "                     u'lat',               u'lon',               u'eta',\n",
    "                 u'sin_hdg',           u'cos_hdg',   u'sin_day_of_week',\n",
    "         u'cos_day_of_week',   u'sin_hour_of_day',   u'cos_hour_of_day',\n",
    "         u'sin_time_of_day',   u'cos_time_of_day',           u'weekday',\n",
    "               u'Braddock ',          u'Downtown',   u'Greenfield Only',\n",
    "             u'McKeesport ', u'Murray-Waterfront',         u'Swissvale',\n",
    "                     u'61A',               u'61B',               u'61C',\n",
    "                     u'61D'],\n",
    "      dtype='object')\n",
    "   bias  pdist  spd        lat        lon  eta   sin_hdg   cos_hdg  \\\n",
    "0   1.0   1106    0  40.439504 -79.996981   16  0.913545 -0.406737   \n",
    "1   1.0   1106    0  40.439504 -79.996981   15  0.913545 -0.406737   \n",
    "2   1.0   1778    8  40.438842 -79.994733   14  0.829038 -0.559193   \n",
    "3   1.0   2934    7  40.437938 -79.991213   13  0.997564 -0.069756   \n",
    "4   1.0   2934    7  40.437938 -79.991213   13  0.997564 -0.069756   \n",
    "\n",
    "   sin_day_of_week  cos_day_of_week ...   Braddock   Downtown  \\\n",
    "0         0.433884        -0.900969 ...         0.0       0.0   \n",
    "1         0.433884        -0.900969 ...         0.0       0.0   \n",
    "2         0.433884        -0.900969 ...         0.0       0.0   \n",
    "3         0.433884        -0.900969 ...         0.0       0.0   \n",
    "4         0.433884        -0.900969 ...         0.0       0.0   \n",
    "\n",
    "   Greenfield Only  McKeesport   Murray-Waterfront  Swissvale  61A  61B  61C  \\\n",
    "0              0.0          0.0                0.0        1.0  1.0  0.0  0.0   \n",
    "1              0.0          0.0                0.0        1.0  1.0  0.0  0.0   \n",
    "2              0.0          0.0                0.0        1.0  1.0  0.0  0.0   \n",
    "3              0.0          0.0                0.0        1.0  1.0  0.0  0.0   \n",
    "4              0.0          0.0                0.0        1.0  1.0  0.0  0.0   \n",
    "\n",
    "   61D  \n",
    "0  0.0  \n",
    "1  0.0  \n",
    "2  0.0  \n",
    "3  0.0  \n",
    "4  0.0  \n",
    "\n",
    "[5 rows x 25 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q3 Linear Regression using Ordinary Least Squares [10 + 4pts]\n",
    "Now you will finally implement a linear regression. As a reminder, linear regression models the data as\n",
    "\n",
    "$$\\mathbf y = \\mathbf X\\mathbf \\beta + \\mathbf \\epsilon$$\n",
    "\n",
    "where $\\mathbf y$ is a vector of outputs, $\\mathbf X$ is also known as the design matrix, $\\mathbf \\beta$ is a vector of parameters, and $\\mathbf \\epsilon$ is noise. We will be estimating $\\mathbf \\beta$ using Ordinary Least Squares, and we recommending following the matrix notation for this problem (https://en.wikipedia.org/wiki/Ordinary_least_squares). \n",
    "\n",
    "### Specification\n",
    "1. We use the numpy term array-like to refer to array like types that numpy can operate on (like Pandas DataFrames). \n",
    "1. Regress the output (eta) on all other features\n",
    "2. Return the predicted output for the inputs in X_test\n",
    "3. Calculating the inverse $(X^TX)^{-1}$ is unstable and prone to numerical inaccuracies. Furthermore, the assumptions of Ordinary Least Squares require it to be positive definite and invertible, which may not be true if you have redundant features. Thus, you should instead use $(X^TX + \\lambda*I)^{-1}$ for identity matrix $I$ and $\\lambda = 10^{-4}$, which for now acts as a numerical \"hack\" to ensure this is always invertible. Furthermore, instead of computing the direct inverse, you should utilize the Cholesky decomposition which is much more stable when solving linear systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LR_model():\n",
    "    \"\"\" Perform linear regression and predict the output on unseen examples. \n",
    "        Attributes: \n",
    "            beta (array_like) : vector containing parameters for the features \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        \"\"\" Initialize the linear regression model by computing the estimate of the weights parameter\n",
    "            Args: \n",
    "                X (array-like) : feature matrix of training data where each row corresponds to an example\n",
    "                y (array like) : vector of training data outputs \n",
    "            \"\"\"\n",
    "        self.beta = np.linalg.solve(X.T.dot(X) +1e-4*np.eye(X.shape[1]),X.T.dot(y))\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X_p): \n",
    "        \"\"\" Predict the output of X_p using this linear model. \n",
    "            Args: \n",
    "                X_p (array_like) feature matrix of predictive data where each row corresponds to an example\n",
    "            Return: \n",
    "                (array_like) vector of predicted outputs for the X_p\n",
    "            \"\"\"\n",
    "        return X_p.dot(self.beta)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided some validation data for you, which is another scrape of the Pittsburgh bus data (but for a different time span). You will need to do the same processing to generate labels and features to your validation dataset. Calculate the mean squared error of the output of your linear regression on both this dataset and the original training dataset. \n",
    "\n",
    "How does it perform? One simple baseline is to make sure that it at least predicts as well as predicting the mean of what you have seen so far. Does it do better than predicting the mean? Compare the mean squared error of a predictor that predicts the mean vs your linear classifier. \n",
    "\n",
    "### Specifications\n",
    "1. Build your linear model using only the training data\n",
    "2. Compute the mean squared error of the predictions on both the training and validation data. \n",
    "3. Compute the mean squared error of predicting the mean of the **training outputs** for all inputs. \n",
    "4. You will need to process the validation dataset in the same way you processed the training dataset.\n",
    "5. You will need to split your features from your output (eta) prior to calling compute_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate mean squared error on both the training and validation set\n",
    "def compute_mse(LR, X, y, X_v, y_v):\n",
    "    \"\"\" Given a linear regression model, calculate the mean squared error for the \n",
    "        training dataset, the validation dataset, and for a mean prediction\n",
    "        Args:\n",
    "            LR (LR_model) : Linear model\n",
    "            X (array-like) : feature matrix of training data where each row corresponds to an example\n",
    "            y (array like) : vector of training data outputs \n",
    "            X_v (array-like) : feature matrix of validation data where each row corresponds to an example\n",
    "            y_v (array like) : vector of validation data outputs \n",
    "        Return: \n",
    "            (train_mse, train_mean_mse, \n",
    "             valid_mse, valid_mean_mse) : a 4-tuple of mean squared errors\n",
    "                                             1. MSE of linear regression on the training set\n",
    "                                             2. MSE of predicting the mean on the training set\n",
    "                                             3. MSE of linear regression on the validation set\n",
    "                                             4. MSE of predicting the mean on the validation set\n",
    "                         \n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    train_mse = float((np.multiply((X.dot(LR.beta)-y),(X.dot(LR.beta)-y))).sum())/y.shape[0]\n",
    "    valid_mse =  float((np.multiply((X_v.dot(LR.beta)-y_v),(X_v.dot(LR.beta)-y_v))).sum())/y_v.shape[0]\n",
    "    train_mean = y.sum()/y.shape[0]\n",
    "    train_mean_mse = float(np.multiply((y-train_mean),(y-train_mean)).sum())/y.shape[0]\n",
    "    valid_mean = y_v.sum()/y_v.shape[0]\n",
    "    \n",
    "    valid_mean_mse = float(np.multiply((y_v-train_mean),(y_v-train_mean)).sum())/y_v.shape[0]\n",
    "    return (train_mse, train_mean_mse,valid_mse, valid_mean_mse)\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[1 1]\n",
      " [2 2]\n",
      " [3 3]]\n",
      "beta [[4]\n",
      " [5]]\n",
      "y [[1]\n",
      " [2]\n",
      " [3]]\n",
      "[[ 8]\n",
      " [16]\n",
      " [24]]\n",
      "[[ 64]\n",
      " [256]\n",
      " [576]]\n",
      "3\n",
      "[[1]\n",
      " [0]\n",
      " [1]]\n",
      "sum 0.666666666667\n",
      "mean 2\n",
      "0\n",
      "[2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "import numpy as np\n",
    "y = np.array([[1],[2],[3]])\n",
    "X = np.array([[1,1],[2,2],[3,3]])\n",
    "beta = np.array([[4],[5]])\n",
    "beta.shape= (2,1)\n",
    "print \"X\", X\n",
    "print \"beta\", beta\n",
    "print \"y\",y\n",
    "print X.dot(beta)-y\n",
    "print np.multiply((X.dot(beta)-y), (X.dot(beta)-y))\n",
    "print y.shape[0]\n",
    "train_mean = y.sum()/y.shape[0]\n",
    "print np.multiply((y-train_mean),(y-train_mean))\n",
    "print \"sum\",float(np.multiply((y-train_mean),(y-train_mean)).sum())/y.shape[0]\n",
    "print \"mean\",train_mean\n",
    "print 1/y.shape[0]*((np.multiply((X.dot(beta)-y), (X.dot(beta)-y))).sum())\n",
    "mse =  np.array([y.sum()/y.shape[0]]*y.shape[0])\n",
    "\n",
    "print mse\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yao\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "# First you should replicate the same processing pipeline as we did to the training set\n",
    "# vdf_valid, pdf_valid = load_data('bus_valid.db')\n",
    "\n",
    "all_trips = split_trips(vdf)\n",
    "all_trips_valid = None\n",
    "\n",
    "labeled_trips_valid = None\n",
    "labeled_vdf_valid = None\n",
    "vdf_features_valid = None\n",
    "vdf_valid, pdf_valid = load_data('bus_valid.db')\n",
    "\n",
    "#all_trips = split_trips(vdf)\n",
    "all_trips_valid = split_trips(vdf_valid)\n",
    "morewood_coordinates = (40.444671114203, -79.94356058465502) # (lat, lon)\n",
    "#label_and_truncate(all_trips[0], morewood_coordinates)\n",
    "\n",
    "labeled_trips_valid = [label_and_truncate(trip, morewood_coordinates) for trip in all_trips_valid]\n",
    "labeled_vdf_valid = pd.concat(labeled_trips_valid).reset_index()\n",
    "vdf_features_valid = None\n",
    "# Separate the features from the output and pass it into your linear regression model.\n",
    "#X_df = None\n",
    "#y_df = None\n",
    "# X_valid_df = None\n",
    "# y_valid_df = None\n",
    "# LR = LR_model(X_df, y_df)\n",
    "# print compute_mse(LR, \n",
    "#                    X_df, \n",
    "#                    y_df, \n",
    "#                    X_valid_df, \n",
    "#                    y_valid_df)\n",
    "\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    16\n",
      "1    15\n",
      "2    14\n",
      "3    13\n",
      "4    13\n",
      "Name: eta, dtype: int64\n",
      "   pdist  spd        lat        lon  bias   sin_hdg   cos_hdg  \\\n",
      "0   1106    0  40.439504 -79.996981   1.0  0.913545 -0.406737   \n",
      "1   1106    0  40.439504 -79.996981   1.0  0.913545 -0.406737   \n",
      "2   1778    8  40.438842 -79.994733   1.0  0.829038 -0.559193   \n",
      "3   2934    7  40.437938 -79.991213   1.0  0.997564 -0.069756   \n",
      "4   2934    7  40.437938 -79.991213   1.0  0.997564 -0.069756   \n",
      "\n",
      "   sin_day_of_week  cos_day_of_week  sin_hour_of_day ...   Swissvale  \\\n",
      "0         0.433884        -0.900969              0.5 ...         1.0   \n",
      "1         0.433884        -0.900969              0.5 ...         1.0   \n",
      "2         0.433884        -0.900969              0.5 ...         1.0   \n",
      "3         0.433884        -0.900969              0.5 ...         1.0   \n",
      "4         0.433884        -0.900969              0.5 ...         1.0   \n",
      "\n",
      "   Downtown  Murray-Waterfront  Braddock   McKeesport   Greenfield Only  61A  \\\n",
      "0       0.0                0.0        0.0          0.0              0.0  1.0   \n",
      "1       0.0                0.0        0.0          0.0              0.0  1.0   \n",
      "2       0.0                0.0        0.0          0.0              0.0  1.0   \n",
      "3       0.0                0.0        0.0          0.0              0.0  1.0   \n",
      "4       0.0                0.0        0.0          0.0              0.0  1.0   \n",
      "\n",
      "   61D  61B  61C  \n",
      "0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "0        19\n",
      "1        18\n",
      "2        16\n",
      "3        15\n",
      "4        14\n",
      "5        14\n",
      "6        14\n",
      "7        14\n",
      "8        14\n",
      "9        14\n",
      "10       14\n",
      "11       14\n",
      "12       14\n",
      "13       14\n",
      "14       13\n",
      "15       13\n",
      "16       13\n",
      "17       13\n",
      "18       10\n",
      "19        9\n",
      "20        9\n",
      "21        8\n",
      "22        8\n",
      "23        8\n",
      "24        8\n",
      "25        8\n",
      "26        7\n",
      "27        7\n",
      "28        6\n",
      "29        7\n",
      "         ..\n",
      "79755     7\n",
      "79756     6\n",
      "79757     4\n",
      "79758     4\n",
      "79759     2\n",
      "79760     2\n",
      "79761    14\n",
      "79762    14\n",
      "79763    14\n",
      "79764    14\n",
      "79765    14\n",
      "79766    14\n",
      "79767    14\n",
      "79768    14\n",
      "79769    15\n",
      "79770    14\n",
      "79771    13\n",
      "79772    12\n",
      "79773    11\n",
      "79774    10\n",
      "79775     8\n",
      "79776     7\n",
      "79777     7\n",
      "79778     6\n",
      "79779     5\n",
      "79780     4\n",
      "79781     3\n",
      "79782     3\n",
      "79783     2\n",
      "79784     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "y_df = vdf_features['eta']\n",
    "X_df = vdf_features.drop(['eta'], axis=1)\n",
    "print y_df.head()\n",
    "print X_df.head()\n",
    "LR = LR_model(X_df, y_df)\n",
    "def eta(row):\n",
    "        #print row['tmstmp'],arrival,type((row['tmstmp']-arrival))\n",
    "        #print arrival, row.name\n",
    "        return (row.prdtm-row.tmstmp).seconds/60\n",
    "tt_eta = merged.apply(eta,axis=1)\n",
    "print tt_eta\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.330539866\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "#y_df = vdf_features['eta']\n",
    "X_merge = merge_features.drop(['eta'], axis=1)\n",
    "lr_eta = LR.predict(X_merge)\n",
    "#print lr_eta\n",
    "real_eta = merged['eta']\n",
    "#print real_eta\n",
    "train_mse = float((np.multiply((lr_eta-real_eta),(lr_eta-real_eta))).sum())/real_eta.shape[0]\n",
    "print train_mse\n",
    "#valid_mse =  float((np.multiply((X_v.dot(LR.beta)-y_v),(X_v.dot(LR.beta)-y_v))).sum())/y_v.shape[0]\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tmstmp   vid        lat        lon  hdg   pid   rt        des  \\\n",
      "0 2016-08-29 16:32:00  5556  40.438023 -79.993688   90  4521  61A  Swissvale   \n",
      "1 2016-08-29 16:33:00  5556  40.437842 -79.990583   91  4521  61A  Swissvale   \n",
      "2 2016-08-29 16:34:00  5556  40.437713 -79.986241   94  4521  61A  Swissvale   \n",
      "3 2016-08-29 16:35:00  5556  40.437537 -79.982502   93  4521  61A  Swissvale   \n",
      "4 2016-08-29 16:36:00  5556  40.437470 -79.981319   94  4521  61A  Swissvale   \n",
      "\n",
      "   pdist  spd tablockid  tatripid  eta  \n",
      "0   2245    0  061A-168      6763   30  \n",
      "1   3127   28  061A-168      6763   29  \n",
      "2   4327   26  061A-168      6763   28  \n",
      "3   5398   26  061A-168      6763   27  \n",
      "4   5720   11  061A-168      6763   26  \n",
      "               tmstmp typ                         stpnm  stpid   vid  dstp  \\\n",
      "0 2016-08-29 16:32:00   A   Forbes Ave opp Morewood Ave   7117  5817    62   \n",
      "1 2016-08-29 16:28:00   A  Forbes Ave past Morewood Ave   4407  5545  8717   \n",
      "2 2016-08-29 16:31:00   A  Forbes Ave past Morewood Ave   4407  5550  7401   \n",
      "3 2016-08-29 16:32:00   A  Forbes Ave past Morewood Ave   4407  5721  6059   \n",
      "4 2016-08-29 16:32:00   A   Forbes Ave opp Morewood Ave   7117  3201  5406   \n",
      "\n",
      "    rt rtdd     rtdir              des               prdtm    dly tablockid  \\\n",
      "0  61D  61D  OUTBOUND  Greenfield Only 2016-08-29 16:33:00  False  061D-285   \n",
      "1  61B  61B   INBOUND         Downtown 2016-08-29 16:36:00  False  061B-203   \n",
      "2  61A  61A   INBOUND         Downtown 2016-08-29 16:38:00  False  061A-172   \n",
      "3   69   69   INBOUND         Downtown 2016-08-29 16:38:00  False  069 -064   \n",
      "4  61C  61C  OUTBOUND      McKeesport  2016-08-29 16:39:00  False  061C-246   \n",
      "\n",
      "   tatripid  \n",
      "0      6094  \n",
      "1      5775  \n",
      "2      6474  \n",
      "3      8916  \n",
      "4      6754  \n",
      "               tmstmp   vid        lat        lon  hdg   pid   rt        des  \\\n",
      "0 2016-08-29 16:32:00  5556  40.438023 -79.993688   90  4521  61A  Swissvale   \n",
      "1 2016-08-29 16:33:00  5556  40.437842 -79.990583   91  4521  61A  Swissvale   \n",
      "2 2016-08-29 16:34:00  5556  40.437713 -79.986241   94  4521  61A  Swissvale   \n",
      "3 2016-08-29 16:35:00  5556  40.437537 -79.982502   93  4521  61A  Swissvale   \n",
      "4 2016-08-29 16:36:00  5556  40.437470 -79.981319   94  4521  61A  Swissvale   \n",
      "\n",
      "   pdist  spd  ...   tatripid  eta  typ                        stpnm stpid  \\\n",
      "0   2245    0  ...       6763   30    A  Forbes Ave opp Morewood Ave  7117   \n",
      "1   3127   28  ...       6763   29    A  Forbes Ave opp Morewood Ave  7117   \n",
      "2   4327   26  ...       6763   28    A  Forbes Ave opp Morewood Ave  7117   \n",
      "3   5398   26  ...       6763   27    A  Forbes Ave opp Morewood Ave  7117   \n",
      "4   5720   11  ...       6763   26    A  Forbes Ave opp Morewood Ave  7117   \n",
      "\n",
      "    dstp  rtdd     rtdir               prdtm    dly  \n",
      "0  15433   61A  OUTBOUND 2016-08-29 16:51:00  False  \n",
      "1  14551   61A  OUTBOUND 2016-08-29 16:51:00  False  \n",
      "2  13351   61A  OUTBOUND 2016-08-29 16:50:00  False  \n",
      "3  12280   61A  OUTBOUND 2016-08-29 16:50:00  False  \n",
      "4  11958   61A  OUTBOUND 2016-08-29 16:50:00  False  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   pdist  spd        lat        lon  eta  bias   sin_hdg       cos_hdg  \\\n",
      "0   2245    0  40.438023 -79.993688   30   1.0  1.000000  6.123234e-17   \n",
      "1   3127   28  40.437842 -79.990583   29   1.0  0.999848 -1.745241e-02   \n",
      "2   4327   26  40.437713 -79.986241   28   1.0  0.997564 -6.975647e-02   \n",
      "3   5398   26  40.437537 -79.982502   27   1.0  0.998630 -5.233596e-02   \n",
      "4   5720   11  40.437470 -79.981319   26   1.0  0.997564 -6.975647e-02   \n",
      "\n",
      "   sin_day_of_week  cos_day_of_week ...   Swissvale  Downtown  McKeesport   \\\n",
      "0              0.0              1.0 ...         1.0       0.0          0.0   \n",
      "1              0.0              1.0 ...         1.0       0.0          0.0   \n",
      "2              0.0              1.0 ...         1.0       0.0          0.0   \n",
      "3              0.0              1.0 ...         1.0       0.0          0.0   \n",
      "4              0.0              1.0 ...         1.0       0.0          0.0   \n",
      "\n",
      "   Murray-Waterfront  Braddock   Greenfield Only  61A  61C  61D  61B  \n",
      "0                0.0        0.0              0.0  1.0  0.0  0.0  0.0  \n",
      "1                0.0        0.0              0.0  1.0  0.0  0.0  0.0  \n",
      "2                0.0        0.0              0.0  1.0  0.0  0.0  0.0  \n",
      "3                0.0        0.0              0.0  1.0  0.0  0.0  0.0  \n",
      "4                0.0        0.0              0.0  1.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "print labeled_vdf_valid.head()\n",
    "print pdf_valid.head()\n",
    "a = labeled_vdf_valid.head()\n",
    "b= pdf_valid.head()\n",
    "merged =labeled_vdf_valid.merge(pdf_valid,  how='inner')\n",
    "#print a\n",
    "print merged.head()\n",
    "merge_features = create_features(merged)\n",
    "print merge_features.head()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check, our training data MSE is approximately 436. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 TrueTime Predictions [5pts]\n",
    "How do you fare against the Pittsburgh Truetime predictions? In this last problem, you will match predictions to their corresponding vehicles to build a dataset that is labeled by TrueTime. Remember that we only evaluate performance on the validation set (never the training set). How did you do?\n",
    "\n",
    "### Specification\n",
    "1. You should use the pd.DataFrame.merge function to combine your vehicle dataframe and predictions dataframe into a single dataframe. You should drop any rows that have no predictions (see the how parameter). (http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html)\n",
    "2. You can compute the TrueTime ETA by taking their predicted arrival time and subtracting the timestamp, and converting that into an integer representing the number of minutes. \n",
    "3. Compute the mean squared error for linear regression only on the rows that have predictions (so only the rows that remain after the merge). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_truetime(LR, labeled_vdf, pdf):\n",
    "    \"\"\" Compute the mse of the truetime predictions and the linear regression mse on entries that have predictions.\n",
    "        Args:\n",
    "            LR (LR_model) : an already trained linear model\n",
    "            labeled_vdf (pd.DataFrame): a dataframe of the truncated and labeled bus data (same as the input to create_features)\n",
    "            pdf (pd.DataFrame): a dataframe of TrueTime predictions\n",
    "        Return: \n",
    "            (tt_mse, lr_mse): a tuple of the TrueTime MSE, and the linear regression MSE\n",
    "        \"\"\"\n",
    "    merged =labeled_vdf.merge(pdf,  how='inner')\n",
    "    merge_features = create_features(merged)\n",
    "    def eta(row):\n",
    "        #print row['tmstmp'],arrival,type((row['tmstmp']-arrival))\n",
    "        #print arrival, row.name\n",
    "        return (row.prdtm-row.tmstmp).seconds/60\n",
    "    tt_eta = merged.apply(eta,axis=1)\n",
    "    X_merge = merge_features.drop(['eta'], axis=1)\n",
    "    lr_eta = LR.predict(X_merge)\n",
    "    #print lr_eta\n",
    "    real_eta = merged['eta']\n",
    "    #print real_eta\n",
    "    lr_mse = float((np.multiply((lr_eta-real_eta),(lr_eta-real_eta))).sum())/real_eta.shape[0]\n",
    "    tt_mse =float((np.multiply((tt_eta-real_eta),(tt_eta-real_eta))).sum())/real_eta.shape[0]\n",
    "    return (tt_mse, lr_mse)\n",
    "    pass\n",
    "    \n",
    "# AUTOLAB_IGNORE_START\n",
    "compare_truetime(LR, labeled_vdf_valid, pdf_valid)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.330539866 51.4144012032\n"
     ]
    }
   ],
   "source": [
    "# tt_mse =float((np.multiply((tt_eta-real_eta),(tt_eta-real_eta))).sum())/real_eta.shape[0]\n",
    "# print train_mse,tt_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, your linear regression MSE should be approximately 60. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Feature Engineering contest (bonus)\n",
    "\n",
    "You may be wondering \"why did we pick the above features?\" Some of the above features may be entirely useless, or you may have ideas on how to construct better features. Sometimes, choosing good features can be the entirety of a data science problem. \n",
    "\n",
    "In this question, you are given complete freedom to choose what and how many features you want to generate. Upon submission to Autolab, we will run linear regression on your generated features and maintain a scoreboard of best regression accuracy (measured by mean squared error). \n",
    "\n",
    "The top scoring students will receive a bonus of 5 points. \n",
    "\n",
    "### Tips:\n",
    "* Test your features locally by building your model using the training data, and predicting on the validation data. Compute the mean squared error on the **validation dataset** as a metric for how well your features generalize. This helps avoid overfitting to the training dataset, and you'll have faster turnaround time than resubmitting to autolab. \n",
    "* The linear regression model will be trained on your chosen features of the same training examples we provide in this notebook. \n",
    "* We test your regression on a different dataset from the training and validation set that we provide for you, so the MSE you get locally may not match how your features work on the Autolab dataset. \n",
    "* We will solve the linear regression using Ordinary Least Squares with regularization $\\lambda=10^{-4}$ and a Cholesky factorization, exactly as done earlier in this notebook. \n",
    "* Note that the argument contains **UNlabeled** data: you cannot build features off the output labels (there is no ETA column). This is in contrast to before, where we kept everything inside the same dataframe for convenience. You can produce the sample input by removing the \"eta\" column, which we provide code for below. \n",
    "* Make sure your features are all numeric. Try everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def contest_features(vdf, vdf_train):\n",
    "    \"\"\" Given a dataframe of UNlabeled and truncated bus data, generate ANY features you'd like for linear regression. \n",
    "        Args:\n",
    "            vdf (dataframe) : dataframe of bus data with truncated rows but unlabeled (no eta column )\n",
    "                              for which you should produce features\n",
    "            vdf_train (dataframe) : dataframe of training bus data, truncated and labeled \n",
    "        Return: \n",
    "            (dataframe) : dataframe of features for each example in vdf\n",
    "        \"\"\"\n",
    "    # create your own engineered features\n",
    "    pass\n",
    "    \n",
    "# AUTOLAB_IGNORE_START\n",
    "contest_cols = list(labeled_vdf.columns)\n",
    "contest_cols.remove(\"eta\")\n",
    "contest_features(labeled_vdf_valid[contest_cols], labeled_vdf).head()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
